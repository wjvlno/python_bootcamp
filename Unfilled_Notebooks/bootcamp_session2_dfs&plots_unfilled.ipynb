{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Working with DataFrames"
      ],
      "metadata": {
        "id": "9ZBFlwT4FfsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Working with DataFrames - Tutorial #1\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Building a DataFrame\n",
        "\n",
        "# We'll start by making a dictionary\n",
        "data = {\n",
        "    \"Make\": [\"Volkswagen\", \"Fiat\", \"Ferrari\", \"Ferrari\"],\n",
        "    \"Model\": [\"Jetta\", \"Panda\", \"250 GTO\", \"California\"],\n",
        "    \"Year\": [2024, 1987, 1963, 2021],\n",
        "    \"Price\": [24875.00, 8200.00, 70000000.00, 255995.00],\n",
        "    \"MPG\": [30, 8.9, 13.8, 25]\n",
        "}\n",
        "\n",
        "# Then convert that dictionary to a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "oSBqS8jWvMob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Working with DataFrames - Tutorial #2\n",
        "\n",
        "# Sorting the DataFrame\n",
        "\n",
        "# Sorting by the 'Price' column in ascending order\n",
        "df_sorted_asc = df.sort_values(by=\"Price\")\n",
        "print(\"\\nDataFrame sorted by Price (ascending):\")\n",
        "print(df_sorted_asc)\n",
        "\n",
        "# Sorting by multiple columns\n",
        "df_sorted_twoCol = df.sort_values(by=[\"Make\", \"Price\"], ascending=[True, False])\n",
        "print(\"\\nDataFrame sorted by Make (ascending) and Price (descending):\")\n",
        "print(df_sorted_twoCol)\n",
        "\n",
        "# Sort by 'Price in descending order\n",
        "df_sorted_desc = ...\n",
        "print(\"\\nDataFrame sorted by Price (descending):\")\n",
        "print(df_sorted_desc)"
      ],
      "metadata": {
        "id": "tz6BQPT2t_kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Working with DataFrames - Task\n",
        "\n",
        "# Create a DataFrame with columns `Product`, `Price`, and `Quantity` with at\n",
        "# least three rows of data\n",
        "\n",
        "# 1. Make your data dictionary first\n",
        "data = ...\n",
        "\n",
        "# 2. Create the DataFrame\n",
        "my_df = ...\n",
        "\n",
        "# Print the DataFrame\n",
        "print(my_df)"
      ],
      "metadata": {
        "id": "rhLgURjfv35K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading and Writing CSVs - Tutorial #1\n",
        "\n",
        "# We'll import the 'os' module to help write file paths for saving/reading\n",
        "import os\n",
        "\n",
        "# set your file destination\n",
        "file_destination = \"C:/Users/wvillano/Downloads\" # replace with your own path\n",
        "\n",
        "# name your CSV\n",
        "filename = \"bootcamp_example.csv\"\n",
        "\n",
        "# Use 'os' to create the full filepath\n",
        "full_path = os.path.join(file_destination, filename)\n",
        "print(full_path)\n",
        "\n",
        "# write your df to a csv file\n",
        "my_df.to_csv(full_path)\n",
        "\n",
        "# read in the csv you just saved under a new variable name\n",
        "my_df_copy = pd.read_csv(full_path)\n",
        "print(my_df_copy)"
      ],
      "metadata": {
        "id": "4uVRWtBmvOOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Indexing and Modifying DataFrames - Tutorial\n",
        "\n",
        "my_df = pd.DataFrame({\n",
        "    \"Product\": [\"Dell XPS 13\", \"Double Espresso\", \"White T-shirt\"],\n",
        "    \"Price\": [1595.00, 3.15, 15.95],\n",
        "    \"Quantity\": [1, 465000, 42]\n",
        "})\n",
        "\n",
        "# Print the original DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "print(my_df)\n",
        "print()\n",
        "\n",
        "# Accessing a column and modifying its elements\n",
        "# Increase the price of all products by 10%\n",
        "my_df[\"Price\"] = my_df[\"Price\"] * 1.20\n",
        "print(\"Uh oh lol! Inflation! Prices are up 20%:\")\n",
        "print(my_df)\n",
        "print()\n",
        "\n",
        "# Accessing a specific element using row and column indices\n",
        "# Change the price of the second element to 50\n",
        "new_price = 50\n",
        "my_df.at[2, \"Price\"] = new_price\n",
        "selected_products = my_df.at[2, 'Product']\n",
        "# Adding ':.2f' to the 'new_price' variable tells python to print 2 decimals\n",
        "print(f\"Changing the price of {selected_products} to ${new_price:.2f}:\")\n",
        "print(my_df)\n",
        "\n",
        "# Use '.loc' to access/modify multiple elements\n",
        "# IMPORTANT: Unlike list slicing, .loc is END INCLUSIVE.\n",
        "# Set the quantity of the first two elements to 0\n",
        "new_quantity = 0\n",
        "my_df.loc[0:1, \"Quantity\"] = new_quantity\n",
        "# this makes a string that combines the two product names\n",
        "selected_products = \" and \".join(my_df.loc[0:1, \"Product\"])\n",
        "print(f\"Changing the quantity of {selected_products} to {new_quantity}:\")\n",
        "print(my_df)\n",
        "print()"
      ],
      "metadata": {
        "id": "oN3IVT_Mv7sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Working with DataFrames (Part 2)"
      ],
      "metadata": {
        "id": "aW0WBYxEAmZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# build df\n",
        "data = {\n",
        "    \"Make\": [\"Volkswagen\", \"Fiat\", \"Ferrari\", \"Ferrari\"],\n",
        "    \"Model\": [\"Jetta\", \"Panda\", \"250 GTO\", \"California\"],\n",
        "    \"Year\": [2024, 1987, 1963, 2021],\n",
        "    \"Price\": [24875.00, 8200.00, 70000000.00, 255995.00],\n",
        "    \"MPG\": [30, 8.9, 13.8, 25]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "## Inspect df\n",
        "\n",
        "# view first few rows of df\n",
        "df.head()\n",
        "\n",
        "# view last 3 rows of df\n",
        "df.tail(3)\n",
        "\n",
        "# view df index (i.e., row names)\n",
        "df.index\n",
        "\n",
        "# view df column names\n",
        "df.columns"
      ],
      "metadata": {
        "id": "ScNXIbUbXR-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Summary stats\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "Yd3E8-2MXVVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Make a copy of our df in case we want to revert changes\n",
        "\n",
        "# this method makes a 'deep' copy\n",
        "df_backup = df.copy()\n",
        "\n",
        "# why not just use df_new = df?? Try it out\n",
        "df_new = ...\n",
        "\n",
        "# try changing the values in a column...\n",
        "df_new[...] = ...\n",
        "\n",
        "print(df_new)\n",
        "print()\n",
        "print(df)\n",
        "\n",
        "# what happened?"
      ],
      "metadata": {
        "id": "pKZjbuBoXYY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# revert df to original\n",
        "\n",
        "df = df_backup.copy() # use 'copy()' again\n",
        "print(df)"
      ],
      "metadata": {
        "id": "R_6GykcZXjrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## DataFrame Assignment\n",
        "\n",
        "# repeat value across all df rows\n",
        "df['MPG'] = 35"
      ],
      "metadata": {
        "id": "YsUXnPcAXwMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Convert DataFrame to different data type / structure\n",
        "df.to_numpy() # e.g., a NumPy array\n",
        "df.to_json()\n",
        "\n",
        "# how can we check other data types that we can convert to with built-in methods?\n",
        "\n",
        "..."
      ],
      "metadata": {
        "id": "2OcdvYsvX2OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Extraction/Selection\n",
        "\n",
        "# Getitem ([])\n",
        "df['MPG'] # returns a series equivalent to df.MPG\n",
        "\n",
        "# Slicing rows\n",
        "df[0:3] # slicing in one dimension will always return rows"
      ],
      "metadata": {
        "id": "7fUzTcy5-X12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Extraction/Selection\n",
        "\n",
        "# '.loc' selects by label(s)\n",
        "df.loc[:, [\"Make\", \"Model\"]] # select all rows (:), specific columns\n",
        "\n",
        "df.loc[1:2, [\"Make\", \"Model\"]] # Note: for row slice, both endpoints are included\n",
        "\n",
        "# Selecting a single row/column returns a scalar value\n",
        "df.loc[0, \"MPG\"]\n",
        "df.at[0, \"MPG\"] # same result. 'at' can only return single values."
      ],
      "metadata": {
        "id": "j1Cepo5RVFKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Extraction/Selection\n",
        "\n",
        "# .iloc selects by position\n",
        "\n",
        "# select a row\n",
        "df.iloc[0] # returns first row of data\n",
        "df.iloc[0,:] # same result\n",
        "\n",
        "# select a full column explicitly\n",
        "df.iloc[:,2]\n",
        "\n",
        "# pull a slice (rows 2-3, columns 1-2)\n",
        "df.iloc[1:3,0:2] # Note: '.iloc' slices like NumPy (start included, endpoint excluded)\n",
        "\n",
        "# pull a single value by position\n",
        "df.iloc[1, 1]\n",
        "df.iat[1, 1] # same result"
      ],
      "metadata": {
        "id": "dvqzuOjAVLni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Extraction/Selection\n",
        "\n",
        "# Boolean indexing\n",
        "df[df['Price'] > 50000]\n",
        "df[df.iloc[:,3] > 50000] # same result\n",
        "\n",
        "# Pull rows where the Make is Ferrari\n",
        "...\n",
        "\n",
        "\n",
        "# multiple boolean conditions\n",
        "df[(df['Make'] == \"Ferrari\") | (df['Make'] == \"Fiat\")] # Make is Ferrari OR ('|') Fiat\n",
        "\n",
        "# Pull rows where the Make is Ferrari AND ('&') the model is California\n",
        "..."
      ],
      "metadata": {
        "id": "U-RwEawaVM47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Setting new values\n",
        "\n",
        "# new column, can be Pandas series, list, numpy array, etc.\n",
        "df[\"Ranking_1\"] = pd.Series([1, 3, 2, 4])\n",
        "df[\"Ranking_2\"] = [1, 3, 2, 4]\n",
        "df[\"Ranking_3\"] = np.array([1, 3, 2, 4])\n",
        "\n",
        "# view\n",
        "df"
      ],
      "metadata": {
        "id": "xFQn9IQcB2zL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Concatenating DataFrames\n",
        "\n",
        "# Original DataFrame\n",
        "data = {\n",
        "    \"Make\": [\"Volkswagen\", \"Fiat\", \"Ferrari\", \"Ferrari\"],\n",
        "    \"Model\": [\"Jetta\", \"Panda\", \"250 GTO\", \"California\"],\n",
        "    \"Year\": [2024, 1987, 1963, 2021],\n",
        "    \"Price\": [24875.00, 8200.00, 70000000.00, 255995.00],\n",
        "    \"MPG\": [30, 8.9, 13.8, 25]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Let's add some more data\n",
        "additional_data = {\n",
        "    \"Make\": [\"Volkswagen\", \"Volkswagen\", \"Volkswagen\", \"Volkswagen\", \"Volkswagen\",\n",
        "             \"Fiat\", \"Fiat\", \"Fiat\", \"Fiat\", \"Fiat\",\n",
        "             \"Ferrari\", \"Ferrari\", \"Ferrari\", \"Ferrari\", \"Ferrari\",\n",
        "             \"Alfa Romeo\", \"Alfa Romeo\", \"Alfa Romeo\", \"Alfa Romeo\", \"Alfa Romeo\",\n",
        "             \"Subaru\", \"Subaru\", \"Subaru\", \"Subaru\", \"Subaru\",\n",
        "             \"Chevrolet\", \"Chevrolet\", \"Chevrolet\", \"Chevrolet\", \"Chevrolet\"],\n",
        "    \"Model\": [\"Golf\", \"Passat\", \"Tiguan\", \"Polo\", \"Arteon\",\n",
        "              \"500\", \"Tipo\", \"Punto\", \"Panda Cross\", \"124 Spider\",\n",
        "              \"488 Spider\", \"F8 Tributo\", \"Portofino\", \"Roma\", \"SF90 Stradale\",\n",
        "              \"Giulia\", \"Stelvio\", \"4C\", \"GTV\", \"Giulietta\",\n",
        "              \"Impreza\", \"Outback\", \"Forester\", \"Crosstrek\", \"WRX\",\n",
        "              \"Malibu\", \"Camaro\", \"Equinox\", \"Tahoe\", \"Traverse\"],\n",
        "    \"Year\": [2022, 2023, 2021, 2020, 2022,\n",
        "             1990, 2018, 2005, 2019, 2017,\n",
        "             2020, 2019, 2021, 2021, 2022,\n",
        "             2021, 2020, 2018, 2019, 2019,\n",
        "             2021, 2020, 2019, 2022, 2022,\n",
        "             2019, 2022, 2021, 2021, 2020],\n",
        "    \"Price\": [23000.00, 27000.00, 25000.00, 22000.00, 35000.00,\n",
        "              9500.00, 18500.00, 15000.00, 12000.00, 25000.00,\n",
        "              280000.00, 320000.00, 215000.00, 222000.00, 625000.00,\n",
        "              43000.00, 41000.00, 56000.00, 45000.00, 39000.00,\n",
        "              23000.00, 27000.00, 25000.00, 24000.00, 36000.00,\n",
        "              25000.00, 35000.00, 32000.00, 45000.00, 40000.00],\n",
        "    \"MPG\": [28, 29, 26, 31, 25,\n",
        "            10, 12, 14, 16, 20,\n",
        "            15, 14, 16, 17, 18,\n",
        "            24, 22, 28, 26, 25,\n",
        "            27, 25, 24, 28, 22,\n",
        "            29, 22, 25, 20, 23]\n",
        "}\n",
        "additional_df = pd.DataFrame(additional_data)\n",
        "\n",
        "# Concatenate the original and additional DataFrames\n",
        "df = pd.concat([df, additional_df], ignore_index=True)\n",
        "\n",
        "# sort by Make, Model name\n",
        "df = df.sort_values(by=[\"Make\", \"Model\"])\n",
        "\n",
        "# view the DataFrame with new data\n",
        "df"
      ],
      "metadata": {
        "id": "aCBRKc4Gw6Op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Operating on DataFrames\n",
        "\n",
        "# Average MPG\n",
        "df['MPG_mean'] = df[\"MPG\"].mean()\n",
        "\n",
        "# SD MPG\n",
        "df['MPG_sd'] = df[\"MPG\"].std()\n",
        "\n",
        "# Add: Median MPG\n",
        "df['MPG_median'] = ...\n",
        "\n",
        "# Add: interquartile range for MPG\n",
        "df['MPG_IQR'] = ...\n",
        "\n",
        "# View df with new columns\n",
        "df"
      ],
      "metadata": {
        "id": "fSeol4PkCTLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average MPG within Make\n",
        "df['MPG_mean_byMake'] = df.groupby('Make')['MPG'].transform('mean')\n",
        "\n",
        "# Is MPG higher than overall average?\n",
        "df = df.assign(MPG_vs_overallMean = np.select([df.MPG < df.MPG_mean, df.MPG > df.MPG_mean], ['Below', \"Above\"], np.nan))\n",
        "\n",
        "# Add: Is MPG higher than average for make?\n",
        "df = ...\n",
        "\n",
        "# View df with new columns\n",
        "df"
      ],
      "metadata": {
        "id": "0WOWR_h0W2GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Aggregation, binning, and filtering\n",
        "\n",
        "# Group by variable and compute averages\n",
        "grouped = df.groupby('Make').agg({'Price': 'mean', 'MPG': 'mean'})\n",
        "print(grouped)\n",
        "\n",
        "# Make MPG bins\n",
        "df = (df.assign(MPG_bin = lambda x: pd.cut(x['MPG'],\n",
        "                                              bins=[0, 15, 25, 10000],\n",
        "                                              labels=[\"<=15\", \"15-25\", \">25\"])))\n",
        "\n",
        "# Add: Flag for most expensive car within each make\n",
        "most_expensive_indices = df.groupby('Make')['Price'].idxmax()\n",
        "df[\"Most_Expensive_inMake\"] = False\n",
        "df.loc[...] = ...\n",
        "\n",
        "# View df with new columns\n",
        "df"
      ],
      "metadata": {
        "id": "mFw8GatMW5ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bonus: Writing functions for data cleaning\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a DataFrame with issues in the Model and Price columns\n",
        "data = {\n",
        "    \"Make\": [\"Volkswagen\", \"Fiat\", \"Ferrari\", \"Ferrari\", \"Volkswagen\", \"Volkswagen\", \"Volkswagen\", \"Volkswagen\", \"Volkswagen\",\n",
        "             \"Fiat\", \"Fiat\", \"Fiat\", \"Fiat\", \"Fiat\",\n",
        "             \"Ferrari\", \"Ferrari\", \"Ferrari\", \"Ferrari\", \"Ferrari\",\n",
        "             \"Alfa Romeo\", \"Alfa Romeo\", \"Alfa Romeo\", \"Alfa Romeo\", \"Alfa Romeo\",\n",
        "             \"Subaru\", \"Subaru\", \"Subaru\", \"Subaru\", \"Subaru\",\n",
        "             \"Chevrolet\", \"Chevrolet\", \"Chevrolet\", \"Chevrolet\", \"Chevrolet\"],\n",
        "    \"Model\": [\"VW Jetta\", \"Panda\", \"250 GTO\", \"California\", \"Volkswagen Golf\", \"Volkswagen Passat\", \"Volkswagen Tiguan\", \"VW Polo\", \"Volkswagen Arteon\",\n",
        "              \"Fiat 500\", \"Fiat Tipo\", \"Fiat Punto\", \"Fiat Panda Cross\", \"Fiat 124 Spider\",\n",
        "              \"Ferrari 488 Spider\", \"Ferrari F8 Tributo\", \"Ferrari Portofino\", \"Ferrari Roma\", \"Ferrari SF90 Stradale\",\n",
        "              \"Alfa Giulia\", \"Stelvio\", \"Alfa 4C\", \"Alfa GTV\", \"Alfa Romeo Giulietta\",\n",
        "              \"Subaru Impreza\", \"Subaru Outback\", \"Subaru Forester\", \"Subaru Crosstrek\", \"Subaru WRX\",\n",
        "              \"Chevrolet Malibu\", \"Chevrolet Camaro\", \"Chevy Equinox\", \"Chevrolet Tahoe\", \"Chevy Traverse\"],\n",
        "    \"Year\": [2024, 1987, 1963, 2021, 2022, 2023, 2021, 2020, 2022,\n",
        "             1990, 2018, 2005, 2019, 2017,\n",
        "             2020, 2019, 2021, 2021, 2022,\n",
        "             2021, 2020, 2018, 2019, 2019,\n",
        "             2021, 2020, 2019, 2022, 2022,\n",
        "             2019, 2022, 2021, 2021, 2020],\n",
        "    \"Price\": [\"$24875\", \"Price is $8200\", \"($70000000)\", \"$255995\", \"$23000\", \"$27000\", \"Price: $25000\", \"€22000\", \"35,000\",\n",
        "              \"9500 dollars\", \"$18500\", \"15k\", \"$12000\", \"25000 USD\",\n",
        "              \"€280000\", \"Price is $320000\", \"$215000\", \"222000\", \"($625000)\",\n",
        "              \"43,000\", \"$41000\", \"56k\", \"$45000\", \"39,000\",\n",
        "              \"23,000\", \"$27000\", \"Price: $25000\", \"24k\", \"36000\",\n",
        "              \"$25000\", \"$35000\", \"$32000\", \"45000\", \"$40000\"]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df = df.sort_values(by = [\"Make\", \"Model\"])\n",
        "\n",
        "# Backup the DataFrame\n",
        "df_backup = df.copy()\n",
        "\n",
        "# View the df\n",
        "# print(df)\n",
        "# print()\n",
        "\n",
        "# There are two issues here:\n",
        "\n",
        "## 1. We have redundant make names in \"Model\" column. E.g., \"Alfa 4C\", \"VW Jetta\"\n",
        "print(df[df[\"Model\"].str.contains(\" \")].Model.values)\n",
        "print()\n",
        "\n",
        "## 2. Prices are formatted weird, and we want straightforward numbers\n",
        "print(df[\"Price\"].values)\n",
        "print()\n",
        "\n",
        "# TASK: brainstorm what steps we should take to fix these issues\n"
      ],
      "metadata": {
        "id": "DjfO1l2BEVNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Bonus: writing functions for data cleaning\n",
        "\n",
        "# Step 1: Fix redundant info in the \"Model\" column\n",
        "\n",
        "# First, we can write a function that works on individual row values in a column\n",
        "\n",
        "def clean_model(row, min_matches=2):\n",
        "    make = row['Make'].lower().replace(' ', '')  # Remove spaces from make name for matching\n",
        "    model = row['Model']\n",
        "\n",
        "    # Split the model name into words\n",
        "    model_words = model.split()\n",
        "\n",
        "    # Remove words with min_matches or more letter matches to the make name, except the last word\n",
        "    cleaned_model_words = []\n",
        "    for i, word in enumerate(model_words):\n",
        "        if i == len(model_words) - 1:\n",
        "            cleaned_model_words.append(word)\n",
        "        else:\n",
        "            # Check if the word has min_matches or more letters from the make\n",
        "            word_lower = word.lower()\n",
        "            match_count = sum(1 for char in word_lower if char in make)\n",
        "            if match_count < min_matches:\n",
        "                cleaned_model_words.append(word)\n",
        "\n",
        "    # Join the remaining words to form the cleaned model name\n",
        "    model = ' '.join(cleaned_model_words)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Then we can apply our function to each row in the 'Model' column using a method in pandas called .apply()\n",
        "\n",
        "df['Model'] = df.apply(clean_model, axis=1)\n",
        "\n",
        "# View the cleaned DataFrame\n",
        "df # Note the changes in the Model column"
      ],
      "metadata": {
        "id": "-fV-Aq-0M8Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "## How does clean_model work? ##################################################\n",
        "################################################################################\n",
        "\n",
        "df = df_backup.copy()\n",
        "\n",
        "# First inspect the input to the function (DataFrame row)\n",
        "\n",
        "# pick a row number to test\n",
        "test_row = 0\n",
        "\n",
        "row = df.iloc[test_row]\n",
        "print(\"Our target row:\")\n",
        "print(row)\n",
        "print()\n",
        "\n",
        "# our function has a default argument, 'min_matches=2', which acts like an input\n",
        "min_matches = 2\n",
        "\n",
        "# Then we'll look at the first variables created in the function (make & model)\n",
        "\n",
        "make = row['Make'].lower().replace(' ', '')  # We're converting this to lowercase and removing spaces\n",
        "print(f\"Make: \\n{make}\")\n",
        "print()\n",
        "\n",
        "model = row['Model']\n",
        "print(f\"Model: \\n{model}\")\n",
        "print()\n",
        "\n",
        "# Split the model name into words\n",
        "\n",
        "model_words = model.split()\n",
        "print(f\"Model Words: \\n{model_words}\")\n",
        "print()\n",
        "\n",
        "# Iterate through the model words, except the last word, and check for matches\n",
        "\n",
        "# Initialize an empty list to hold the cleaned model words\n",
        "cleaned_model_words = []\n",
        "\n",
        "# Enumerate through the model words to get both the index and the word\n",
        "for i, word in enumerate(model_words):\n",
        "    # If this is the last word, always add it to the cleaned_model_words list\n",
        "    print(f\"Current word: {word}\")\n",
        "    if i == len(model_words) - 1:\n",
        "        print(f\"Keep the last word in the model name: {word}\")\n",
        "        cleaned_model_words.append(word)\n",
        "    else:\n",
        "        # Convert the word to lowercase for comparison\n",
        "        word_lower = word.lower()\n",
        "        print(f\"Current word (to lowercase): {word_lower}\")\n",
        "\n",
        "        # Count the number of characters in the word that are also in the make name\n",
        "        match_count = sum(1 for char in word_lower if char in make)\n",
        "        print(f\"Match count for '{word_lower}' with make '{make}': {match_count}\")\n",
        "\n",
        "        # If the match count is less than the minimum matches, add the word to cleaned_model_words\n",
        "        if match_count < min_matches:\n",
        "            print(f\"Appending word (less than {min_matches} matches): {word}\")\n",
        "            cleaned_model_words.append(word)\n",
        "        else:\n",
        "            print(f\"Target word (has {match_count} matching characters): {word}\")\n",
        "    print()\n",
        "\n",
        "# The cleaned_model_words list now contains the filtered model words\n",
        "print()\n",
        "print(f\"Cleaned Model Name: {cleaned_model_words}\")\n",
        "print()"
      ],
      "metadata": {
        "id": "2SklGHUrNItb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Clean the \"Price\" column\n",
        "\n",
        "# First, we can write a function that works on individual row values in a column\n",
        "\n",
        "def clean_price(price):\n",
        "    # Convert price to lowercase for consistent processing\n",
        "    price = price.lower()\n",
        "\n",
        "    # Handle 'k' for thousands\n",
        "    if 'k' in price:\n",
        "        price = price.replace('k', '000')\n",
        "\n",
        "    # Handle conversion from euros to dollars\n",
        "    euro_to_dollar_rate = 1.1\n",
        "    if '€' in price or 'eur' in price:\n",
        "        price = price.replace('€', '').replace('eur', '').strip()\n",
        "        is_euro = True\n",
        "    else:\n",
        "        is_euro = False\n",
        "\n",
        "    # Remove non-numeric characters except for periods\n",
        "    num_str = ''\n",
        "    for char in price:\n",
        "        if char.isdigit() or char == '.':\n",
        "            num_str += char\n",
        "\n",
        "    # Convert to float if possible\n",
        "    if num_str:\n",
        "        price = float(num_str)\n",
        "        if is_euro:\n",
        "            price *= euro_to_dollar_rate\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "    return price\n",
        "\n",
        "# Then we can apply our function to each row in the 'Price' column using a method in pandas called .apply()\n",
        "\n",
        "df['Price'] = ...\n",
        "\n",
        "# View the cleaned DataFrame\n",
        "df # Note that prices are converted to numeric values and standardized to dollars"
      ],
      "metadata": {
        "id": "tTomrZWCNAsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "## How does clean_price work? ##################################################\n",
        "################################################################################\n",
        "\n",
        "df = df_backup.copy()\n",
        "\n",
        "test_row = 12\n",
        "row = df.iloc[test_row]\n",
        "\n",
        "# Inspect the input to the function\n",
        "\n",
        "price = row['Price']\n",
        "print(\"Original Price:\")\n",
        "print(price)\n",
        "print()\n",
        "\n",
        "# Convert price to lowercase for consistent processing\n",
        "\n",
        "price = price.lower()\n",
        "\n",
        "# Handle 'k' for thousands\n",
        "\n",
        "if 'k' in price:\n",
        "    print(\"'k' detected\")\n",
        "    price = price.replace('k', '000')\n",
        "    print(f\"'k' to thousands: {price}\")\n",
        "else:\n",
        "    print(\"No 'k' detected\")\n",
        "print()\n",
        "\n",
        "# Handle conversion from euros to dollars\n",
        "\n",
        "euro_to_dollar_rate = 1.1\n",
        "if '€' in price or 'eur' in price:\n",
        "    price = price.replace('€', '').replace('eur', '').strip()\n",
        "    is_euro = True\n",
        "else:\n",
        "    is_euro = False\n",
        "print(f\"Price in Euro?: {is_euro}\")\n",
        "print()\n",
        "\n",
        "# Remove non-numeric characters except for periods\n",
        "\n",
        "num_str = ''\n",
        "for char in price:\n",
        "    if char.isdigit() or char == '.':\n",
        "        num_str += char\n",
        "\n",
        "# Convert to float if possible\n",
        "\n",
        "if num_str:\n",
        "    price = float(num_str)\n",
        "    if is_euro:\n",
        "        price *= euro_to_dollar_rate\n",
        "        print(f\"Final Price (euro to USD): {price}\")\n",
        "    else:\n",
        "        print(f\"Final Price (already in USD): {price}\")"
      ],
      "metadata": {
        "id": "yrnVFIvINLtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting"
      ],
      "metadata": {
        "id": "gi_eshIgA2ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Load Python plotting modules\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set seaborn style for the plots\n",
        "sns.set(style=\"whitegrid\")"
      ],
      "metadata": {
        "id": "Ep0kEA4AZfiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Subplotted histograms of \"MPG\", \"Price\", \"Year\"\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Histogram for MPG\n",
        "sns.histplot(df['MPG'], bins=10, kde=True, ax=axes[0])\n",
        "axes[0].set_title('Histogram of MPG')\n",
        "\n",
        "# Histogram for Price\n",
        "sns.histplot(df['Price'], bins=10, kde=True, ax=axes[1])\n",
        "axes[1].set_title('Histogram of Price')\n",
        "\n",
        "# Histogram for Year\n",
        "sns.histplot(df['Year'], bins=10, kde=True, ax=axes[2])\n",
        "axes[2].set_title('Histogram of Year')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "11yxuGNc9LuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. MPG by Price (line with dots)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=df, x='Price', y='MPG', marker='o')\n",
        "plt.title('MPG by Price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fY8Y5idG5ymy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing price outliers\n",
        "Q1 = df['Price'].quantile(0.25)\n",
        "Q3 = df['Price'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "price_filtered_df = df[~((df['Price'] < (Q1 - 1.5 * IQR)) | (df['Price'] > (Q3 + 1.5 * IQR)))]\n",
        "\n",
        "# MPG by Price without outliers\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=price_filtered_df, x='Price', y='MPG', marker='o', errorbar=None)\n",
        "plt.title('MPG by Price (Without Outliers)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GvQwajvsZTO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Boxplot with violins for MPG within make\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.violinplot(x='Make', y='MPG', data=df, inner=None, palette=\"vlag\", alpha = 0.3)\n",
        "sns.boxplot(x='Make', y='MPG', data=df, whis=[0, 100], width=.2, palette=\"vlag\")\n",
        "plt.title('Boxplot with Violins for MPG within Make')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TtPPhT8T9eXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Boxplot with violins for Price within make\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.violinplot(x='Make', y='Price', data=df, inner=None, color=\".8\")\n",
        "sns.boxplot(x='Make', y='Price', data=df, whis=[0, 100], width=.2, palette=\"vlag\")\n",
        "plt.title('Boxplot with Violins for Price within Make')\n",
        "plt.show()\n",
        "\n",
        "# Filter out the Ferrari 250 GTO as an outlier\n",
        "price_filtered_df_ferrari = df[~((df['Make'] == 'Ferrari') & (df['Model'] == '250 GTO'))]\n",
        "\n",
        "# Boxplot with violins for Price within make (without Ferrari 250 GTO)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.violinplot(x='Make', y='Price', data=price_filtered_df_ferrari, inner=None, color=\".8\")\n",
        "sns.boxplot(x='Make', y='Price', data=price_filtered_df_ferrari, whis=[0, 100], width=.2, palette=\"vlag\")\n",
        "plt.title('Boxplot with Violins for Price within Make (Without Ferrari 250 GTO)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6mu8UFKs9o-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task: Make a boxplot with violins for Price within make (without any Ferrari)\n",
        "..."
      ],
      "metadata": {
        "id": "yHpneYJLZHdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. MPG by Price with individual colored dots and lines within each make, removing Price outliers\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.lineplot(data=price_filtered_df, x='Price', y='MPG', hue='Make', marker='o', style='Make', palette='tab10')\n",
        "plt.title('MPG by Price with Individual Colored Dots and Lines within Each Make (Without Outliers)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yTUShO8r9puh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}